강화학습 part 3 - ORPO

KAIST AI - 2024년 3월 14일자 논문
https://arxiv.org/pdf/2403.07691.pdf

https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi?usp=sharing

ORPO는 새로운 미세조정(fine-tuning) 기술로, 전통적인 supervised fine-tuning과 preference alignment 단계를 하나의 과정으로 통합해 수행함.

이를 통해 훈련에 필요한 계산 자원과 시간을 줄일 수 있음. 또한 실험 결과에 따르면 ORPO는 다양한 모델 크기와 벤치마크에서 다른 alignment 방법들보다 뛰어난 성능을 보임.(PPO, DPO)

![image](https://github.com/jinuk0211/rlfh/assets/150532431/b7e33762-b9d6-475f-8f46-694f9167d312)

![image](https://github.com/jinuk0211/rlfh/assets/150532431/5ba507a1-6bcf-4574-81a1-890b3df53d39)

